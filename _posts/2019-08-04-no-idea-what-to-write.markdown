---
layout: post
title:  "不是迷途的羔羊"
date:   2019-08-04 21:30:00 +0800
date_update: 2019-08-09 01:02:00 +0800
categories: 流水账
tags: [心情,随想,记录]
author: 幽玄
use_mathjax: true
---

## 2019.8.4

犹豫了很久，也不知道写啥，就随便写两句话吧。

## 2019.8.7

在考虑要不要回去一趟，现在还有些时间，不过似乎也没法待太久。可是回去也不知道做啥，大概就是看看家里人，陪伴他们几天。

贝壳家里有事回去了，下周才能回来，现在只剩下我一个人在屋里。有点寂寞，也有点不安，突然发现自己有点不太习惯完全一个人待着了，尽管我也并不喜欢总和其他人待在一起，宁可一个人。

在想着弄这个博客写什么东西呢，其实我就想写点乱七八糟的，心情，情绪，胡思乱想，什么也不是。大概就是让思绪游荡，完全也不整理，让它自由自在的晃荡着。

中午吃什么呢？已经没有菜了，只剩下红薯，辣椒，一点水果，差不多这样，米和面都还有。如果要做饭吃的话，得去买菜。

这两天开了药也没用起来，还是觉得太不方便了，在想要不要专门买些装备，但是也觉得很麻烦，而且以后就没啥用了，有点浪费。药如果不用的话，钱感觉也白花了，而且自己还是难受，这个也得赶紧想想。

盼着贝壳赶紧回来，希望一切都好。这几天我是不是要回家呢。话说我又吃点什么好。药得赶紧用起来。心里现在正想着这四件事情。

晚上18:10，把饭蒸上了。还是去超市买点菜吧，需要买葱、洗手液，买点蔬菜，买两个鸡腿。晚上查一下电费，另外看看燃气费怎么查。

做了一个苦瓜炒鸡蛋，一个青椒腊肉，感觉还行，比较合自己的口味。算是第一次自己一个人做饭，还算可以。剩饭盛出来了，准备明天炒蛋炒饭。电费还是没有查到，支付宝上看不到，电话查询提示功能没有开通，微信查询又需要查询密码，总之搞得好麻烦。燃气费就完全不知道了，不管了，还是等账单吧。

上周末看了《哪吒之魔童降世》，确实非常精彩，一个是剧情比较意外，没有想到哪吒成了魔丸，和龙三太子有了这样的展开，李靖如此深沉的父爱，这些设计感觉和之前的哪吒完全不一样，耳目一新，另一个就是视觉上的冲击了，尤其是打斗，动作流畅，画面精细，很是震撼。

之前买了苋菜，结果到晚上发现很多都烂了，才知道这种蔬菜得当天买当天做了吃，要不然容易烂，尤其是洗过之后（感觉超市上架之前可能用水冲过？）。第二天做菜的时候扔了很多，最后炒出来只有碗底的一点点。

<span>&#9876;</span>**记录几个代码**：
- 一个交通流量预测的代码：
{% include icon-github.html username="bbklk" %} /
[LRA-for-traffic-flow-forecasting](https://github.com/bbklk/LRA-for-traffic-flow-forecasting)。这个可能主要是帮助了解一下任务和数据集。
- DeepGCN的代码：
{% include icon-github.html username="lightaime" %} /
[deep_gcns](https://github.com/lightaime/deep_gcns)，这是ICCV 2019的Oral论文，项目主页：[Can GCNs Go as Deep as CNNs?](https://sites.google.com/view/deep-gcns)，给出了Tensorflow和Pytorch的实现。
- RetinaFace的代码：[deepinsight/insightface/RetinaFace](https://github.com/deepinsight/insightface/tree/master/RetinaFace)。
- CVPR 2018的工作，Structure Inference Net：
{% include icon-github.html username="choasup" %} /
[SIN](https://github.com/choasup/SIN)；另外这似乎是作者的博客：[Choas Blog 有一个梦想 并非遥不可及](https://choasup.github.io/)。

<span>&#9876;</span>**关于二次型的最大和最小值**，要求是单位向量，那解就是矩阵的最大和最小特征值，可以用拉格朗日乘数法求解，参考资料：[William F. Trench - THE METHOD OF
LAGRANGE MULTIPLIERS](http://ramanujan.math.trinity.edu/wtrench/texts/TRENCH_LAGRANGE_MULTIPLIERS.PDF)（第9页）。

最近要规划一些论文的阅读，ICCV 2019的论文马上就要大波袭来，之前还有好多没看，然后[arXiv](https://arxiv.org/list/cs.CV/recent)上每天都有大量新论文，虽然很多没什么看的必要。
- [CVPR 2019](http://openaccess.thecvf.com/CVPR2019.py)
- [ICML 2019](https://icml.cc/Conferences/2019/Videos)

HTML中的一些特殊符号：[W3Schools - UTF-8 Miscellaneous Symbols - Range: Decimal 9728-9983 Hex 2600-26FF](https://www.w3schools.com/charsets/ref_utf_symbols.asp)。

网易云音乐上一个感觉不错的歌单：[咕噜咕噜patience - 沈以诚\徐秉龙\方宇杰\焦迈奇\孟凡明\姜鹏](https://music.163.com/playlist?id=2220042776&userid=525816)。

好了，今天的流水账就记到这里吧。

## 2019.8.8

[知乎专栏 - 空调一开一关费电，还是一直开着费电？](https://zhuanlan.zhihu.com/p/40331879)结论就是一开一关更加费电，可能的原因在于“由于空调在启动时的瞬时电流往往较大，如果反复启动，耗电量会相应增加，同时不利于空调的保养。”

[CCAI2018演讲实录 - 蒲慕明：脑科学与类脑机器学习2018-10-16](https://pan.baidu.com/s/1B7-phZ0ibT8LCYrqRWItAQ)。

<span>&#9876;</span>**加性高斯过程**，发表于NIPS 2011：[Additive Gaussian Processes (NIPS 2011)](https://papers.nips.cc/paper/4221-additive-gaussian-processes)，[arXiv 1112.4394](https://arxiv.org/abs/1112.4394)。二作的个人主页：[Hannes Nickisch](http://hannes.nickisch.org/)。

关于各种免费图床：[知乎专栏 - 盘点一下免费好用的图床](https://zhuanlan.zhihu.com/p/35270383)，感觉可以考虑[SM.MS](https://sm.ms/)，试了一下，不需要注册，可以直接粘贴图像内容（例如截图之后去网页上直接粘贴），还提供各种引用格式（例如HTML、Markdown等），挺好用的。但是我想尽量还是别用太多图，因为图通常本身比较大，可能耗费流量，也影响页面加载速度。

对近期图森的工作AlignDet的讨论：[知乎 - 如何评价目标检测模型AlignDet？Revisiting Feature Alignment for One-stage Object Detection](https://www.zhihu.com/question/338959309)。回答里面有提到一些类似和相关的工作：
- Dual Refinement Networks for Accurate and Fast Object Detection in Real-World Scenes ([arXiv 1807.08638](https://arxiv.org/abs/1807.08638))
- Propose-and-Attend Single Shot Detector ([arXiv 1907.12736](https://arxiv.org/abs/1907.12736))
- Cascade RetinaNet: Maintaining Consistency for Single-Stage Object Detection (BMVC 2019, [arXiv 1907.06881](https://arxiv.org/abs/1907.06881))
- RepPoints: Point Set Representation for Object Detection (ICCV 2019, [arXiv 1904.11490](https://arxiv.org/abs/1904.11490))，另外，RepPoints作者认为图森这个AlignDet的工作是RepPoints的特例（其实就是他们的基线模型），并分析了[实现上的一些差异](https://www.zhihu.com/question/338959309/answer/780428729)。

今天查最大似然估计和最大后验估计的时候，发现[ESL](https://web.stanford.edu/~hastie/ElemStatLearn/)的一个小错误，我手头纸质版本的232页公式(8.23)，分母的积分应该是对参数\\(\theta\\)而不是对数据\\(\mathbf{Z}\\)，否则分母上\\(\mathbf{Z}\\)都积分积没了，怎么会得到“后验”呢。
